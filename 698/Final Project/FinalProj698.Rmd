---
title: "698FinalProject"
author: "Joshua Registe"
date: "4/20/2021"
output:
  rmdformats::readthedown:
    self_contained: yes
    thumbnails: yes
    lightbox: yes
    gallery: no
    highlight: tango
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(lubridate)
library(RColorBrewer)
library(scales)
library(tidymodels)
library(Hmisc)
library(skimr)
library(ggcorrplot)
library(kableExtra)
library(janitor)
library(tidyselect)
library(outliers)
library(stringr)
library(ggpmisc)
library(caret)
```


```{r Custom Functions}

getSeason <- function(DATES) {
  #funtion to return the season of a given date
  WS <- as.Date("2012-12-21", format = "%Y-%m-%d") # Winter Solstice
  SE <- as.Date("2012-3-20",  format = "%Y-%m-%d") # Spring Equinox
  SS <- as.Date("2012-6-20",  format = "%Y-%m-%d") # Summer Solstice
  FE <- as.Date("2012-9-22",  format = "%Y-%m-%d") # Fall Equinox
  # Convert dates from any year to 2012 dates
  d <- as.Date(strftime(DATES, format="2012-%m-%d"))
  
  ifelse (d >= WS | d < SE, "Winter",
          ifelse (d >= SE & d < SS, "Spring",
                  ifelse (d >= SS & d < FE, "Summer", "Fall")))
}

variableImportancePlot <- function(model=NULL, chart_title='Variable Importance Plot') {
  # Make sure a model was passed
  if (is.null(model)) {
    return
  }
  
  # use caret and gglot to print a variable importance plot
  varImp(model) %>% as.data.frame() %>% top_n(n = 6) %>% 
    ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall)) +
    geom_col(aes(fill = Overall)) +
    theme(panel.background = element_blank(),
          panel.grid = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    scale_fill_gradient() +
    labs(title = chart_title,
         x = "Parameter",
         y = "Relative Importance")
}

```


```{r Custom Constants}
#PoP represents the period of performance for them to meet chlorination
PoP<-as.Date(c("11/01/2015","11/01/2016"),"%m/%d/%Y")
# Dechlor represents the date they upgraded their chlorination facility
Dechlor<-as.Date(c("03/01/2016"),"%m/%d/%Y")
# Theme for ggplots
defaulttheme<-theme(panel.background = element_blank(),
                            panel.border = element_rect(color = "black", fill=NA))

```

Importing the data and removing Flow as it follows different time series stamp
```{r importing data}
# this chunk just focuses on importing the data
# 
path <- "data/raw/CombinedDataSetsTrimmed.xlsx"
sheetnames <- excel_sheets(path)
mylist <- lapply(excel_sheets(path), read_excel, path = path)
# name the dataframes
names(mylist) <- sheetnames
rm(path,sheetnames)

mylist<-mylist[1:7]

```


```{r Wide Conversion}
# Over here we simply join all the items from the list and get the season of Date
 PR_Wide<-mylist %>% reduce(left_join, by = "Date")

PR_Wide$Season<-getSeason(as.Date(PR_Wide$Date,format = "%Y-%m-%d"))

PR_Wide %>% select(function(x) is.numeric(x)) %>% 
  cor(method = "pearson") %>% as.data.frame() %>%  
  rownames_to_column() %>% 
  pivot_longer(cols = -rowname, names_to = "Param", values_to = "Value") %>% 
  filter(is.na(Value)==F) %>% 
  filter(!(Param==rowname)) %>% 
  arrange(-Value)

skim(PR_Wide)
```


```{r Distribution Exploration}


PR_Wide %>% 
DataExplorer::plot_histogram()



```

```{r missing data, fig.height=12}
PR_Wide %>% 
DataExplorer::plot_missing()
naniar::miss_var_summary(PR_Wide)
```
```{r Defining Data}
PR_Wide$Chlorineexceedance<-if_else(PR_Wide$Chlorine_ResidualEffluent__mgperL_Daily_Average>0.52,"Exceedance","Non_Exceedance") 

PR_Wide<-PR_Wide %>% 
  filter(Date>=as.Date(Dechlor)) %>%  
  mutate_if(is.character,factor)


missingrow_limit<-.5*nrow(PR_Wide)
retain_row<-apply(PR_Wide, MARGIN = 1, function(y) sum(length(which(is.na(y))))) < missingrow_limit
PR_Wide[!retain_row,]
PR_Wide<- PR_Wide[retain_row,]

missingcol_limit<-.6*ncol(PR_Wide)
retain_col<-apply(PR_Wide, MARGIN = 2, function(y) sum(length(which(is.na(y))))) < missingcol_limit

df<-PR_Wide[,retain_col,]

names(df)<- str_replace_all(names(df),"\\.+","")

default_removals<-
  c("CHLORINE_RESIDUALMAX",
    "CHLORINE_RESIDUALSMPL",
    "Date",
    "DAY",
    "ResidualperTarget",
    "CHL_RES_AT_TIME_OF_FECAL_SAMPLE",
    "Date")

df1<-df %>% 
  select(-c(default_removals, 
         Chlorine_ResidualEffluent__mgperL_Daily_Average))

df2<-df %>% 
  select(-c(Chlorineexceedance,
            default_removals))
```


```{r Defining Models}
#(baseline<-prop.table(table(df$Chlorineexceedance)))
set.seed(2)
Datasplit<- initial_split(df2, prop = .75)
Datatrain<-training(Datasplit)
datatest<-testing(Datasplit)
datacv<- vfold_cv(Datatrain, v = 10)


parsnip::model_db %>% filter(mode == "regression") 

engine_tree<-
  decision_tree(mode = "regression") %>% 
  set_engine(engine = "rpart")

engine_forest<-
  rand_forest(mode = "regression") %>% 
  set_engine(engine = "ranger", importance = 'impurity')

engine_xgb<-
  boost_tree(mode = "regression") %>% 
  set_engine(engine = "xgboost")


engine_cube<-
  boost_tree(mode = "regression") %>% 
  set_engine(engine = "C5.0")

engine_svmpoly<-
  svm_poly(mode = "regression") %>% 
  set_engine(engine = "kernlab")

engine_lm<-
  linear_reg(mode = "regression") %>% 
  set_engine(engine = "lm")

```


```{r Data Transformation Steps}

recipe1<-
  recipe(Chlorine_ResidualEffluent__mgperL_Daily_Average ~ ., data = Datatrain) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.9) %>%
  step_other(all_nominal_predictors()) %>% 
  step_impute_median(all_numeric_predictors()) %>% 
  step_impute_mode(all_nominal_predictors()) %>% 
  #step_BoxCox(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_nzv(all_predictors())
```

```{r}
steps <-recipe1 %>% prep()

steps$steps[[1]]
steps$steps[[2]]
steps$steps[[3]]
steps$steps[[4]]
steps$steps[[6]]
#steps$steps[[7]]


```

```{r}

wf_dt<-
  workflow() %>% 
  add_model(engine_tree) %>% 
  add_recipe(recipe1)

wf_rf<-
  workflow() %>% 
  add_model(engine_forest) %>% 
  add_recipe(recipe1)

wf_lm<-
  workflow() %>% 
  add_model(engine_lm) %>% 
  add_recipe(recipe1)

wf_svmpoly<-
  workflow() %>% 
  add_model(engine_svmpoly) %>% 
  add_recipe(recipe1)


wf_xgb<-
  workflow() %>% 
  add_model(engine_xgb) %>% 
  add_recipe(recipe1)
```


```{r Decision Tree}

wf_fit<-
  wf_dt %>% parsnip::fit(data = Datatrain)

Model_results<- function(model){
M_results <-
  bind_rows(
    predict(wf_fit, new_data = Datatrain) %>% 
      mutate(
        truth = Datatrain$Chlorine_ResidualEffluent__mgperL_Daily_Average,
        model = model,
        set = "Training Set"
      ),
    predict(wf_fit, new_data = datatest)  %>% 
      mutate(
        truth = datatest$Chlorine_ResidualEffluent__mgperL_Daily_Average,
        model = model,
        set = "Testing Set"
      )
    )
return(M_results)
}

M_results<-Model_results("Decision Tree")

vp_dt<-varImp(wf_fit$fit$fit$fit) %>% arrange(-Overall) %>% mutate(model = "Decision Tree")

```

```{r Random Forest}

wf_fit<-
  wf_rf %>% parsnip::fit(data = Datatrain)

  M_results<-bind_rows(M_results, Model_results("Random_forest"))

vp_rf<-wf_fit$fit$fit$fit$variable.importance %>% as.data.frame() %>% rename("Overall" = ".") %>% arrange(-Overall) %>% mutate(model = "Random Forest")


```

```{r Multiple Linear Regression}

wf_fit<-
  wf_lm %>% parsnip::fit(data = Datatrain)

  M_results<-bind_rows(M_results, Model_results("Multiple Linear Regression"))

vp_lm<-varImp(wf_fit$fit$fit$fit) %>% arrange(-Overall) %>% mutate(model = "Multiple Linear Regression")


```

```{r XG Boost}

wf_fit<-
  wf_xgb %>% parsnip::fit(data = Datatrain)

  M_results<-bind_rows(M_results, Model_results("XG Boost"))

vp_xgb<-xgboost::xgb.importance(feature_names = names(recipe1 %>% prep() %>% bake(Datatrain)), model = wf_fit$fit$fit$fit) %>% select(Feature,Gain) %>% rename(Overall = Gain) %>% arrange(Overall)
```


```{r SVM Poly}

wf_fit<-
  wf_svmpoly %>% parsnip::fit(data = Datatrain)

  M_results<-bind_rows(M_results, Model_results("Polynomial SVM"))


```








```{r}
M_results %>% group_by(set, model) %>%
  yardstick::metrics(truth = "truth", estimate = ".pred" )

```

```{r, fig.width==15}
M_results %>% 
  ggplot(aes(y = truth,x = .pred))+
  geom_point(pch =21, alpha = 0.3, fill = "skyblue") +
  geom_smooth(method = "lm", color = "red3") +
  facet_wrap(set~model,  nrow = 2)+
  stat_poly_eq(aes(label = paste(..adj.rr.label.., sep = "~~~")), 
               label.x.npc = "right", label.y.npc = .9,
               formula = y~x, parse = TRUE, size = 2.5)+
  theme(panel.background = element_blank(),
        panel.grid = element_blank())+
  coord_cartesian(xlim=c(.25,1.25), ylim = c(0,1.25))+
  geom_hline(yintercept = .52, linetype = 2, color = "grey50")+
  geom_vline(xintercept = .52, linetype = 2, color = "grey50")+
  labs(x = "Actual Value",
       y = "Predicted Value",
       subtitle = "Dashed Line Represents Water Quality Exceedance")
```

```{r}
parsnip::show_model_info("rand_forest")


engine_rf<-
  rand_forest(mode = "regression",
                mtry = tune(), #the minimum improvement in model needed at each node
                trees = tune(), #The maximum depth of the tree allowed
                min_n = tune()) %>% 
  set_engine("ranger", importance = "impurity")

tree_grid <- expand.grid(mtry = seq(2,3,4),trees = seq(0,1000,250), min_n = seq(2,8,2))
rf_rs <- tune_grid(
  object =  engine_rf,
  preprocessor = recipe1,
  resamples = datacv,
  grid = tree_grid,
  metrics = metric_set(rmse, rsq)
)

rf_rs %>% autoplot()+theme_light(base_family = "IBMPlexSans")



              
              
```
```{r}
final_tree <- finalize_model(engine_rf, select_best(rf_rs, "rsq"))

final_tree
```


```{r}
final_wf<-
  workflow() %>% 
  add_model(final_tree) %>% 
  add_recipe(recipe1)
```


```{r}
wf_fit<-
  final_wf %>% parsnip::fit(data = Datatrain)

  M_results<-bind_rows(M_results, Model_results("Random_forest_Final"))

vp_rf<-wf_fit$fit$fit$fit$variable.importance %>% as.data.frame() %>% rename("Overall" = ".") %>% arrange(-Overall) %>% mutate(model = "Random Forest")

```

```{r}

M_results %>% 
  filter(grepl("Random",model)) %>% 
  ggplot(aes(y = truth,x = .pred))+
  geom_point(pch =21, alpha = 0.3, fill = "skyblue") +
  geom_smooth(method = "lm", color = "red3") +
  facet_wrap(set~model,  nrow = 2)+
  stat_poly_eq(aes(label = paste(..adj.rr.label.., sep = "~~~")), 
               label.x.npc = "right", label.y.npc = .9,
               formula = y~x, parse = TRUE, size = 2.5)+
  theme(panel.background = element_blank(),
        panel.grid = element_blank())+
  coord_cartesian(xlim=c(.25,1.25), ylim = c(0,1.25))+
  geom_hline(yintercept = .52, linetype = 2, color = "grey50")+
  geom_vline(xintercept = .52, linetype = 2, color = "grey50")+
  labs(x = "Actual Value",
       y = "Predicted Value",
       subtitle = "Dashed Line Represents Water Quality Exceedance")
```

```{r, fig.height=10}
vp_dt<-vp_dt %>% rownames_to_column(var = "Feature")
vp_lm<-vp_lm %>% rownames_to_column(var = "Feature")
vp_rf<-vp_rf %>% rownames_to_column(var = "Feature")
vp_xgb<-vp_xgb %>% mutate(model = "XG Boost")
variableimp <-bind_rows(vp_dt,vp_lm,vp_xgb,vp_rf)

library(tidytext)

variableimp %>% group_by(model) %>% 
  arrange(-Overall, .by_group = T) %>% 
  slice_max(n = 6, order_by = Overall) %>% 
  ungroup() %>% 
  mutate(model = as.factor(model),
           Feature = reorder_within(Feature, -Overall, model)) %>%
    ggplot(aes(x = Feature, y = Overall)) +
    geom_col(fill = "skyblue") +
  facet_wrap(~model, scales = "free")+
    theme(panel.background = element_blank(),
          panel.grid = element_blank(),
          axis.text.x = element_text(angle = 90)) +
    scale_x_reordered() +
    labs(title = "Variable Importance",
         x = "Parameter",
         y = "Relative Importance")

```




